{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Deploying Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We`ll use the same model we trained and evaluated previously - the churn prediction model.  Now we'll deploy it as a web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Introduction\n",
    "\n",
    "- What we will cover this week\n",
    "\n",
    "\n",
    "<img src=\"../images/overview_week5.png\" alt=\"overview\" style=\"width:500px;height:auto;\">\n",
    "\n",
    "- saving and loading models\n",
    "- serving the model with Flask\n",
    "\n",
    "<img src=\"../images/docker_on_AWS_EB.png\" alt=\"docker on AWS EB\" style=\"width:500px;height:auto;\">\n",
    "\n",
    "- environment and dependency management with pipenv\n",
    "- environment docker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Saving and loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving the model to pickle\n",
    "- Loading the model from pickle\n",
    "- Turning our notebook into a Python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "categorical_columns = list(df.dtypes[df.dtypes == \"object\"].index)\n",
    "\n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors=\"coerce\")\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    "\n",
    "df.churn = (df.churn == \"yes\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [\"tenure\", \"monthlycharges\", \"totalcharges\"]\n",
    "\n",
    "categorical = [\n",
    "    \"gender\",\n",
    "    \"seniorcitizen\",\n",
    "    \"partner\",\n",
    "    \"dependents\",\n",
    "    \"phoneservice\",\n",
    "    \"multiplelines\",\n",
    "    \"internetservice\",\n",
    "    \"onlinesecurity\",\n",
    "    \"onlinebackup\",\n",
    "    \"deviceprotection\",\n",
    "    \"techsupport\",\n",
    "    \"streamingtv\",\n",
    "    \"streamingmovies\",\n",
    "    \"contract\",\n",
    "    \"paperlessbilling\",\n",
    "    \"paymentmethod\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(max_iter=10_000, C=C)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient=\"records\")\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 0.842 +- 0.007\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.churn.values\n",
    "    y_val = df_val.churn.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print(\"C=%s %.3f +- %.3f\" % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8444081607020903,\n",
       " 0.8449522414249768,\n",
       " 0.8335741521171984,\n",
       " 0.8347609036260152,\n",
       " 0.851769633836403]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584492508693815"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.churn.values, C=1.0)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "\n",
    "y_test = df_test.churn.values\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pickel library and save the model to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the file where the model will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/model_C=1.0.bin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = f\"../models/model_C={C}.bin\"\n",
    "output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: simple save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open(output_file, \"wb\")\n",
    "pickle.dump((dv, model), f_out)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: save with open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(output_file, \"wb\") as f_out:\n",
    "#     pickle.dump((dv, model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the pickle library and load the model from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"../models/model_C=1.0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_file, \"rb\") as f_in:\n",
    "    (dv, model) = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(max_iter=10000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a customer and predict the churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 12,\n",
    "    'monthlycharges': 2.85,\n",
    "    'totalcharges': 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dv.transform([customer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5394495644561959"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making requests (create a separate notebook for that)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [04_predict_test.ipynb](04_predict_test.ipynb)\n",
    "- Export file to [Python script](../predict.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Web services: introduction to Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Writing a simple ping/pong app -> `ping.py`\n",
    "- strat it with `python ping.py`\n",
    "- Querying it with `curl` and browser\n",
    "\n",
    "```bash\n",
    "curl http://localhost:9696/ping\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "curl http://0.0.0.0:9696/ping\n",
    "```\n",
    "\n",
    "or open in browser [http://localhost:9696/ping](http://localhost:9696/ping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Serving the churn model with Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wrappping the `predict.py` script into a Flask app\n",
    "- Querying it with `requests`\n",
    "- Preparing for production: gunicorn\n",
    "- Running it on Windows? with waitress\n",
    "\n",
    "\n",
    "Start the server with:\n",
    "```bash\n",
    "gunicorn --bind 0.0.0.0:9696 predict:app\n",
    "```\n",
    "\n",
    "Test the server with:\n",
    "```bash\n",
    "python predict_test.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Dependency and environment management: Pipenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why we need virtual environment\n",
    "\n",
    "<img src=\"../images/python_envs.png\" alt=\"Python envs\" style=\"width:500px;height:auto;\">\n",
    "<img src=\"../images/python_envs2.png\" alt=\"Python envs 2\" style=\"width:500px;height:auto;\">\n",
    "<img src=\"../images/python_env_manager.png\" alt=\"Python envs 2\" style=\"width:500px;height:auto;\">\n",
    "\n",
    "- Installing Pipenv\n",
    "- Installing libraries with Pipenv\n",
    "- Running things with Pipenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUG: could not create virtual environment with python 3.8, so I created an [environment](../environment.yml) with python 3.11.3 and scikit-learn=1.5.2. `Pipfile.lock` could not be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Pipenv\n",
    "\n",
    "```bash\n",
    "pip install pipenv\n",
    "```\n",
    "\n",
    "### Activating the virtual environment\n",
    "\n",
    "```bash\n",
    "pipenv shell\n",
    "```\n",
    "\n",
    "### Deactivating the virtual environment\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n",
    "\n",
    "### Removing the virtual environment\n",
    "\n",
    "```bash\n",
    "pipenv --rm\n",
    "```\n",
    "\n",
    "\n",
    "### Installing environment from Pipfile\n",
    "\n",
    "```bash\n",
    "pipenv install\n",
    "```\n",
    "\n",
    "### Running commands with Pipenv\n",
    "\n",
    "```bash\n",
    "pipenv run gunicorn --bind 0.0.0.0:9696 predict:app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Environment management: Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why we need Docker\n",
    "\n",
    "<img src=\"../images/docker.png\" alt=\"Docker\" style=\"width:500px;height:auto;\">\n",
    "<img src=\"../images/docker_to_cloud.png\" alt=\"Docker to cloud\" style=\"width:500px;height:auto;\">\n",
    "\n",
    "- Running a Python image with docker\n",
    "- Dockerfile\n",
    "- Building a docker image\n",
    "- Running a docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Python image with docker\n",
    "\n",
    "```bash\n",
    "docker run -it --rm --entrypoint=bash python:3.8.12-slim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Dockerfile](../Dockerfile)\n",
    "\n",
    "```Dockerfile\n",
    "FROM python:3.8.12-slim                                 # define base image\n",
    "\n",
    "WORKDIR /app # define working directory\n",
    "COPY [\"Pipfile\", \"Pipfile.lock\", \"./\"]                  # copy files for python environment to working directory\n",
    "\n",
    "RUN pipenv install --system --deploy                    # install dependencies from Pipfile to system\n",
    "\n",
    "COPY [\"predict.py\", \"./models/model_C=1.0.bin\", \"./\"]   # copy flask-app and model-files to working directory\n",
    "\n",
    "EXPOSE 9696                                             # expose port\n",
    "\n",
    "ENTRYPOINT [ \"gunicorn\", \"--bind=0.0.0.0:9696\", \"predict:app\" ] # define entrypoint, start gunicorn and run app\n",
    "```\n",
    "\n",
    "<img src=\"../images/docker_expose_port.png\" alt=\"docker expose port\" style=\"width:500px;height:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a docker image\n",
    "\n",
    "```bash\n",
    "docker build -t churn-predictor .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a docker image\n",
    "\n",
    "```bash\n",
    "docker run -it --rm -p 9696:9696 churn-predictor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Deployment to the cloud: AWS Elastic Beanstalk (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Installing the eb cli\n",
    "- Running eb locally\n",
    "- Deploying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/AWS_beanstalk.png\" alt=\"AWS beanstalk\" style=\"width:500px;height:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the eb cli\n",
    "\n",
    "On your AWS EC2 instance in your conda environment run:\n",
    "\n",
    "```bash\n",
    "pipenv install awsebcli --dev\n",
    "```\n",
    "\n",
    "### Activate the virtual environment\n",
    "\n",
    "```bash\n",
    "pipenv shell\n",
    "```\n",
    "\n",
    "### Initialize the Elastic Beanstalk application\n",
    "\n",
    "```bash\n",
    "eb init -p docker -r eu-central-1 churn-serving\n",
    "```\n",
    "\n",
    "### Running eb locally\n",
    "\n",
    "```bash\n",
    "eb local run --port 9696\n",
    "```\n",
    "\n",
    "### Deploying the model\n",
    "\n",
    "```bash\n",
    "eb create churn-serving-env\n",
    "```\n",
    "\n",
    "change `predict_test.py` to use the new URL, given by the Elastic Beanstalk\n",
    "\n",
    "```python\n",
    "host = 'churn-serving-env.eba-xxxxxx.eu-west-1.elasticbeanstalk.com'\n",
    "url = f'http://{host}/predict'\n",
    "```\n",
    "\n",
    "### Cleaning up\n",
    "\n",
    "```bash\n",
    "eb terminate churn-serving-env\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">[!Warning]\n",
    ">\n",
    ">Be careful, this is open to the whole world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save model with pickle\n",
    "- Use Flask to turn the model into a web service\n",
    "- Use a dependency & env manager\n",
    "- Package it with Docker\n",
    "- Deploy to the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Explore more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flask is not the only framework for creating web services. Try others, e.g. FastAPI\n",
    "- Experiment with other ways of managing environment, e.g. virtual env, conda, poetry.\n",
    "- Expolore other ways of deploying web services, e.g. GCP, Azure, Heroku, Python Anywhere, etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChurnPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
