{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import nessessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from IPython.display import Image  # for displaying images\n",
    "from PIL import Image\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "# !pip install pylabel > /dev/null\n",
    "\n",
    "#!pip install pylabel\n",
    "\n",
    "from pylabel import *\n",
    "from pylabel import importer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.5419 0.5162 0.9163 0.9684\n"
     ]
    }
   ],
   "source": [
    "# An example annotation\n",
    "!cat ../data/split_yolo/labels/test/american_pit_bull_terrier_0007.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "  - dogue_de_bordeaux\n",
      "  - staffordshire_bullterrier\n",
      "  - dogo_argentino\n",
      "  - other_dog_breed\n",
      "  - cau_ovcharka\n",
      "  - person\n",
      "  - human_face\n",
      "  - am_pit_bull_terrier\n",
      "  - fila_brasileiro\n",
      "  - bull_terrier\n",
      "  - kangal\n",
      "  - neapolitan_mastiff\n",
      "  - rottweiler\n",
      "  - bull_mastiff\n",
      "  - mastin_espanol\n",
      "  - tosa_inu\n",
      "  - am_staffordshire_terrier\n",
      "  - mastiff\n",
      "nc: 18\n",
      "path: ../data/split_yolo\n",
      "test: /Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo/images/test\n",
      "train: /Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo/images/train\n",
      "val: /Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo/images/val\n"
     ]
    }
   ],
   "source": [
    "# An example YAML file\n",
    "!cat ../data/split_yolo/dataset.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Image and annotation folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has one folder (\"../data/renamed_dub_removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_93434\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_93434_level0_row0\" class=\"row_heading level0 row0\" >Dataset Directory</th>\n",
       "      <td id=\"T_93434_row0_col0\" class=\"data row0 col0\" >../data/split_yolo/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93434_level0_row1\" class=\"row_heading level0 row1\" >Image Directory</th>\n",
       "      <td id=\"T_93434_row1_col0\" class=\"data row1 col0\" >../data/split_yolo/train/images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93434_level0_row2\" class=\"row_heading level0 row2\" >Labels Directory</th>\n",
       "      <td id=\"T_93434_row2_col0\" class=\"data row2 col0\" >../data/split_yolo/train/labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x30406f6d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to stored dataset\n",
    "dataset_dir = Path(\"../data/split_yolo/train\")\n",
    "# Create dataset dir if not exists\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "img_dir = dataset_dir / \"images\"\n",
    "labels_dir = dataset_dir / \"labels\"\n",
    "\n",
    "pd.Series({\"Dataset Directory\": dataset_dir,\n",
    "           \"Image Directory\": img_dir,\n",
    "           \"Labels Directory\": labels_dir}).to_frame().style.hide(axis=\"columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Image File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_files(\n",
    "    img_dir: Path,  # The directory to search for image files\n",
    "    img_fmts=[\"jpg\", \"jpeg\", \"png\"],  # The list of image formats to search for\n",
    "):\n",
    "    \"\"\"\n",
    "    Get all the image files in the given directory.\n",
    "\n",
    "    Returns:\n",
    "    img_paths (list): A list of pathlib.Path objects representing the image files\n",
    "    \"\"\"\n",
    "    img_paths = []\n",
    "\n",
    "    # Use the glob module to search for image files with specified formats\n",
    "    for fmt in img_fmts:\n",
    "        img_paths.extend(glob(f\"{img_dir}/*.{fmt}\"))\n",
    "    # Convert the file paths to pathlib.Path objects\n",
    "    img_paths = [Path(path) for path in img_paths]\n",
    "\n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image file has a unique name that we can use to locate the corresponding annotation data. We can make a dictionary that maps image names to file paths. The dictionary will allow us to retrieve the file path for a given image more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 1079\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9e781\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9e781_level0_row0\" class=\"row_heading level0 row0\" >bull_mastiff_0120</th>\n",
       "      <td id=\"T_9e781_row0_col0\" class=\"data row0 col0\" >../data/split_yolo/train/images/bull_mastiff_0120.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e781_level0_row1\" class=\"row_heading level0 row1\" >dogo_argentino_0003</th>\n",
       "      <td id=\"T_9e781_row1_col0\" class=\"data row1 col0\" >../data/split_yolo/train/images/dogo_argentino_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e781_level0_row2\" class=\"row_heading level0 row2\" >dogo_argentino_0017</th>\n",
       "      <td id=\"T_9e781_row2_col0\" class=\"data row2 col0\" >../data/split_yolo/train/images/dogo_argentino_0017.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e781_level0_row3\" class=\"row_heading level0 row3\" >cau_ovcharka_0045</th>\n",
       "      <td id=\"T_9e781_row3_col0\" class=\"data row3 col0\" >../data/split_yolo/train/images/cau_ovcharka_0045.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e781_level0_row4\" class=\"row_heading level0 row4\" >fila_brasileiro_0039</th>\n",
       "      <td id=\"T_9e781_row4_col0\" class=\"data row4 col0\" >../data/split_yolo/train/images/fila_brasileiro_0039.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3043ad6d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all image files in the 'img_dir' directory\n",
    "img_dict = {\n",
    "    file.stem: file  # Create a dictionary that maps file names to file paths\n",
    "    for file in get_img_files(\n",
    "        img_dir\n",
    "    )  # Get a list of image files in the image directory\n",
    "}\n",
    "\n",
    "# Print the number of image files\n",
    "print(f\"Number of Images: {len(img_dict)}\")\n",
    "\n",
    "# Display the first five entries from the dictionary using a Pandas DataFrame\n",
    "pd.DataFrame.from_dict(img_dict, orient=\"index\").head().style.hide(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Path.glob at 0x116248e10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir.glob(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/split_yolo/train/labels/american_pit_bull_terrier_0076.txt'),\n",
       " PosixPath('../data/split_yolo/train/labels/rottweiler_0066.txt'),\n",
       " PosixPath('../data/split_yolo/train/labels/neapolitan_mastiff_0024.txt'),\n",
       " PosixPath('../data/split_yolo/train/labels/american_pit_bull_terrier_0062.txt'),\n",
       " PosixPath('../data/split_yolo/train/labels/cau_ovcharka_0147.txt')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files = list(labels_dir.glob('*'))\n",
    "annotation_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train\n",
      "Images exist: True\n",
      "Labels exist: True\n",
      "Number of labels: 1079\n",
      "Split: val\n",
      "Images exist: True\n",
      "Labels exist: True\n",
      "Number of labels: 393\n",
      "Split: test\n",
      "Images exist: True\n",
      "Labels exist: True\n",
      "Number of labels: 279\n"
     ]
    }
   ],
   "source": [
    "# filepath: debug.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "yaml_path = \"/Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo/\"\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "for split in splits:\n",
    "    img_path = os.path.join(yaml_path, \"images\", split)\n",
    "    label_path = os.path.join(yaml_path, \"labels\", split)\n",
    "    print(f\"Split: {split}\")\n",
    "    print(f\"Images exist: {os.path.exists(img_path)}\")\n",
    "    print(f\"Labels exist: {os.path.exists(label_path)}\")\n",
    "    if os.path.exists(label_path):\n",
    "        print(f\"Number of labels: {len(os.listdir(label_path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total label files found: 1751\n",
      "Sample label content:\n",
      "2 0.4776 0.5251 0.7631 0.8952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filepath: debug.py\n",
    "import glob\n",
    "\n",
    "label_files = glob.glob(os.path.join(yaml_path, \"labels/**/*.txt\"))\n",
    "print(f\"Total label files found: {len(label_files)}\")\n",
    "\n",
    "# Check first label file content\n",
    "if label_files:\n",
    "    with open(label_files[0], \"r\") as f:\n",
    "        print(f\"Sample label content:\\n{f.read()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN SPLIT:\n",
      "Images: 1079\n",
      "Labels: 1079\n",
      "Missing labels: 0\n",
      "Missing images: 0\n",
      "\n",
      "VAL SPLIT:\n",
      "Images: 393\n",
      "Labels: 393\n",
      "Missing labels: 0\n",
      "Missing images: 0\n",
      "\n",
      "TEST SPLIT:\n",
      "Images: 279\n",
      "Labels: 279\n",
      "Missing labels: 0\n",
      "Missing images: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Set, Dict, List\n",
    "\n",
    "\n",
    "def check_file_matches(yaml_path: str) -> Dict[str, Dict[str, Set[str]]]:\n",
    "    \"\"\"\n",
    "    Compare image and label filenames across train/val/test splits\n",
    "\n",
    "    Args:\n",
    "        yaml_path: Path to dataset root directory\n",
    "\n",
    "    Returns:\n",
    "        Dict containing filename sets for each split\n",
    "    \"\"\"\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    results = {}\n",
    "\n",
    "    for split in splits:\n",
    "        # Get paths\n",
    "        img_path = os.path.join(yaml_path, \"images\", split)\n",
    "        label_path = os.path.join(yaml_path, \"labels\", split)\n",
    "\n",
    "        # Get filenames without extensions\n",
    "        img_files = (\n",
    "            {\n",
    "                Path(f).stem\n",
    "                for f in os.listdir(img_path)\n",
    "                if f.endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "            }\n",
    "            if os.path.exists(img_path)\n",
    "            else set()\n",
    "        )\n",
    "        label_files = (\n",
    "            {Path(f).stem for f in os.listdir(label_path) if f.endswith(\".txt\")}\n",
    "            if os.path.exists(label_path)\n",
    "            else set()\n",
    "        )\n",
    "\n",
    "        results[split] = {\n",
    "            \"images\": img_files,\n",
    "            \"labels\": label_files,\n",
    "            \"missing_labels\": img_files - label_files,\n",
    "            \"missing_images\": label_files - img_files,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run check\n",
    "yaml_path = \"/Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo\"\n",
    "results = check_file_matches(yaml_path)\n",
    "\n",
    "for split, data in results.items():\n",
    "    print(f\"\\n{split.upper()} SPLIT:\")\n",
    "    print(f\"Images: {len(data['images'])}\")\n",
    "    print(f\"Labels: {len(data['labels'])}\")\n",
    "    print(f\"Missing labels: {len(data['missing_labels'])}\")\n",
    "    print(f\"Missing images: {len(data['missing_images'])}\")\n",
    "\n",
    "    if data[\"missing_labels\"]:\n",
    "        print(f\"Sample missing labels: {list(data['missing_labels'])[:5]}\")\n",
    "    if data[\"missing_images\"]:\n",
    "        print(f\"Sample missing images: {list(data['missing_images'])[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN:\n",
      "Total images: 1079\n",
      "Total labels: 1079\n",
      "Exact match: True\n",
      "\n",
      "VAL:\n",
      "Total images: 393\n",
      "Total labels: 393\n",
      "Exact match: True\n",
      "\n",
      "TEST:\n",
      "Total images: 279\n",
      "Total labels: 279\n",
      "Exact match: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Set, Dict, List\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def check_matching_files(yaml_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Check if image and label filenames match exactly\n",
    "\n",
    "    Args:\n",
    "        yaml_path (str): Path to dataset root\n",
    "\n",
    "    Returns:\n",
    "        Dict: Results of filename matching analysis\n",
    "    \"\"\"\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    results = defaultdict(dict)\n",
    "\n",
    "    for split in splits:\n",
    "        # Get paths\n",
    "        img_dir = Path(yaml_path) / \"images\" / split\n",
    "        label_dir = Path(yaml_path) / \"labels\" / split\n",
    "\n",
    "        # Get filenames without extensions\n",
    "        img_files = sorted([f.stem for f in img_dir.glob(\"*.jpg\")])\n",
    "        label_files = sorted([f.stem for f in label_dir.glob(\"*.txt\")])\n",
    "\n",
    "        # Check exact matches\n",
    "        img_set = set(img_files)\n",
    "        label_set = set(label_files)\n",
    "\n",
    "        results[split] = {\n",
    "            \"img_files\": img_files,\n",
    "            \"label_files\": label_files,\n",
    "            \"exact_match\": img_set == label_set,\n",
    "            \"img_only\": list(img_set - label_set),\n",
    "            \"label_only\": list(label_set - img_set),\n",
    "            \"total_imgs\": len(img_files),\n",
    "            \"total_labels\": len(label_files),\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run analysis\n",
    "yaml_path = \"/Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo\"\n",
    "matches = check_matching_files(yaml_path)\n",
    "\n",
    "for split, data in matches.items():\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"Total images: {data['total_imgs']}\")\n",
    "    print(f\"Total labels: {data['total_labels']}\")\n",
    "    print(f\"Exact match: {data['exact_match']}\")\n",
    "\n",
    "    if not data[\"exact_match\"]:\n",
    "        print(\"Images without labels:\", data[\"img_only\"][:5])\n",
    "        print(\"Labels without images:\", data[\"label_only\"][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing train ===\n",
      "Label path: ../data/split_yolo/labels/train\n",
      "Image path: ../data/split_yolo/images/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing YOLO files...:   0%|          | 0/1079 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No image file found: ../data/split_yolo/labels/train/../data/split_yolo/images/train/american_pit_bull_terrier_0076.jpg. Check path_to_images and img_ext arguments.\n",
      "\n",
      "=== Processing val ===\n",
      "Label path: ../data/split_yolo/labels/val\n",
      "Image path: ../data/split_yolo/images/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing YOLO files...:   0%|          | 0/393 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No image file found: ../data/split_yolo/labels/val/../data/split_yolo/images/val/neapolitan_mastiff_0030.jpg. Check path_to_images and img_ext arguments.\n",
      "\n",
      "=== Processing test ===\n",
      "Label path: ../data/split_yolo/labels/test\n",
      "Image path: ../data/split_yolo/images/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing YOLO files...:   0%|          | 0/279 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No image file found: ../data/split_yolo/labels/test/../data/split_yolo/images/test/staffordshire_bullterrier_0146.jpg. Check path_to_images and img_ext arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pylabel import importer\n",
    "\n",
    "\n",
    "def debug_yolo_import(yaml_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Debug YOLO import process with detailed logging\n",
    "\n",
    "    Args:\n",
    "        yaml_path: Path to YAML file\n",
    "    \"\"\"\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    for split in splits:\n",
    "        print(f\"\\n=== Processing {split} ===\")\n",
    "\n",
    "        # Construct paths\n",
    "        label_path = Path(yaml_path).parent / \"labels\" / split\n",
    "        img_path = Path(yaml_path).parent / \"images\" / split\n",
    "\n",
    "        print(f\"Label path: {label_path}\")\n",
    "        print(f\"Image path: {img_path}\")\n",
    "\n",
    "        # Try importing single split\n",
    "        try:\n",
    "            dataset = importer.ImportYoloV5(\n",
    "                path=str(label_path), path_to_images=str(img_path), img_ext=\"jpg\"\n",
    "            )\n",
    "            print(f\"DataFrame shape: {dataset.df.shape}\")\n",
    "            print(f\"img_id values: {dataset.df['img_id'].unique()}\")\n",
    "            print(f\"Sample data:\\n{dataset.df.head()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "\n",
    "# Run debug\n",
    "yaml_file = \"../data/split_yolo/dataset.yaml\"\n",
    "debug_yolo_import(yaml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN ===\n",
      "Label dir: ../data/split_yolo/labels/train\n",
      "Image dir: ../data/split_yolo/images/train\n",
      "Sample image exists: True\n",
      "Sample paths:\n",
      "  Label: ../data/split_yolo/labels/train/american_pit_bull_terrier_0076.txt\n",
      "  Image: ../data/split_yolo/images/train/american_pit_bull_terrier_0076.jpg\n",
      "\n",
      "=== VAL ===\n",
      "Label dir: ../data/split_yolo/labels/val\n",
      "Image dir: ../data/split_yolo/images/val\n",
      "Sample image exists: True\n",
      "Sample paths:\n",
      "  Label: ../data/split_yolo/labels/val/neapolitan_mastiff_0030.txt\n",
      "  Image: ../data/split_yolo/images/val/neapolitan_mastiff_0030.jpg\n",
      "\n",
      "=== TEST ===\n",
      "Label dir: ../data/split_yolo/labels/test\n",
      "Image dir: ../data/split_yolo/images/test\n",
      "Sample image exists: True\n",
      "Sample paths:\n",
      "  Label: ../data/split_yolo/labels/test/staffordshire_bullterrier_0146.txt\n",
      "  Image: ../data/split_yolo/images/test/staffordshire_bullterrier_0146.jpg\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import os\n",
    "\n",
    "def debug_yolo_paths(yaml_path: str) -> Dict[str, Dict[str, Path]]:\n",
    "    \"\"\"\n",
    "    Debug YOLO dataset paths and verify file access\n",
    "    \n",
    "    Args:\n",
    "        yaml_path: Path to YAML file\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing verified paths\n",
    "    \"\"\"\n",
    "    base_path = Path(yaml_path).parent\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    paths = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        # Construct absolute paths\n",
    "        label_path = base_path / \"labels\" / split\n",
    "        img_path = base_path / \"images\" / split\n",
    "        \n",
    "        # Verify first image exists\n",
    "        first_label = next(label_path.glob(\"*.txt\"))\n",
    "        img_name = first_label.stem + \".jpg\"\n",
    "        img_file = img_path / img_name\n",
    "        \n",
    "        paths[split] = {\n",
    "            \"label_dir\": label_path,\n",
    "            \"image_dir\": img_path,\n",
    "            \"sample_label\": first_label,\n",
    "            \"sample_image\": img_file,\n",
    "            \"exists\": img_file.exists()\n",
    "        }\n",
    "    \n",
    "    return paths\n",
    "\n",
    "# Test paths\n",
    "yaml_file = \"../data/split_yolo/dataset.yaml\"\n",
    "path_info = debug_yolo_paths(yaml_file)\n",
    "\n",
    "for split, info in path_info.items():\n",
    "    print(f\"\\n=== {split.upper()} ===\")\n",
    "    print(f\"Label dir: {info['label_dir']}\")\n",
    "    print(f\"Image dir: {info['image_dir']}\")\n",
    "    print(f\"Sample image exists: {info['exists']}\")\n",
    "    print(f\"Sample paths:\")\n",
    "    print(f\"  Label: {info['sample_label']}\")\n",
    "    print(f\"  Image: {info['sample_image']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing train ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing YOLO files...:  73%|███████▎  | 787/1079 [00:02<00:00, 300.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing train: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "=== Testing val ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing YOLO files...: 100%|██████████| 393/393 [00:01<00:00, 258.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Found 628 annotations\n",
      "\n",
      "=== Testing test ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing YOLO files...: 100%|██████████| 279/279 [00:00<00:00, 418.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Found 413 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pylabel import importer\n",
    "\n",
    "\n",
    "def test_yolo_import(yaml_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Test YOLO import with absolute paths\n",
    "\n",
    "    Args:\n",
    "        yaml_file (str): Path to YAML config\n",
    "    \"\"\"\n",
    "    # Convert to absolute paths\n",
    "    base_path = Path(yaml_file).parent.resolve()\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    for split in splits:\n",
    "        print(f\"\\n=== Testing {split} ===\")\n",
    "\n",
    "        # Construct absolute paths\n",
    "        label_dir = base_path / \"labels\" / split\n",
    "        img_dir = base_path / \"images\" / split\n",
    "\n",
    "        try:\n",
    "            dataset = importer.ImportYoloV5(\n",
    "                path=str(label_dir), path_to_images=str(img_dir), img_ext=\"jpg\"\n",
    "            )\n",
    "            print(f\"Success! Found {len(dataset.df)} annotations\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error importing {split}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Test with absolute paths\n",
    "yaml_file = Path(\"../data/split_yolo/dataset.yaml\").resolve()\n",
    "test_yolo_import(str(yaml_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid images: 1078\n",
      "Invalid images: 1\n",
      "\n",
      "Problem files:\n",
      "  - ../data/split_yolo/images/train/dogue_de_bordeaux_0088.jpg\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "def debug_train_images(base_path: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Debug train split images for loading issues\n",
    "\n",
    "    Args:\n",
    "        base_path: Path to dataset root\n",
    "\n",
    "    Returns:\n",
    "        Tuple of valid and invalid image paths\n",
    "    \"\"\"\n",
    "    train_path = Path(base_path) / \"images\" / \"train\"\n",
    "    valid_images = []\n",
    "    invalid_images = []\n",
    "\n",
    "    for img_path in sorted(train_path.glob(\"*.jpg\")):\n",
    "        try:\n",
    "            # Attempt to load image\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                invalid_images.append(str(img_path))\n",
    "            else:\n",
    "                valid_images.append(str(img_path))\n",
    "        except Exception as e:\n",
    "            invalid_images.append(f\"{str(img_path)}: {str(e)}\")\n",
    "\n",
    "    return valid_images, invalid_images\n",
    "\n",
    "\n",
    "# Test train split\n",
    "base_path = \"../data/split_yolo\"\n",
    "valid, invalid = debug_train_images(base_path)\n",
    "\n",
    "print(f\"Valid images: {len(valid)}\")\n",
    "print(f\"Invalid images: {len(invalid)}\")\n",
    "if invalid:\n",
    "    print(\"\\nProblem files:\")\n",
    "    for f in invalid:\n",
    "        print(f\"  - {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo/images/train/dogue_de_bordeaux_0088.jpg: GIF image data, version 89a, 400 x 300\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def check_file_info(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Get file info using file command\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to image file\n",
    "\n",
    "    Returns:\n",
    "        str: File command output\n",
    "    \"\"\"\n",
    "    result = subprocess.run([\"file\", file_path], capture_output=True, text=True)\n",
    "    return result.stdout.strip()\n",
    "\n",
    "\n",
    "# Check specific file\n",
    "target_file = \"/Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo/images/train/dogue_de_bordeaux_0088.jpg\"\n",
    "print(check_file_info(target_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image has 2 frames\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def check_gif_frames(image_path: str) -> Tuple[int, bool]:\n",
    "    \"\"\"\n",
    "    Check number of frames in image file\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to image file\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, bool]: Number of frames, is_gif flag\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    try:\n",
    "        n_frames = img.n_frames\n",
    "        print(f\"Image has {n_frames} frames\")\n",
    "        return n_frames, True\n",
    "    except AttributeError:\n",
    "        print(\"Not an animated image\")\n",
    "        return 1, False\n",
    "\n",
    "\n",
    "# Check image\n",
    "image_path = \"/Users/tillmeineke/ML/ML_Zoomcamp2024_hw/helloListenDog/data/split_yolo/images/train/dogue_de_bordeaux_0088.jpg\"\n",
    "frames, is_gif = check_gif_frames(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem file: ![Problem file](../data/split_yolo/images/train/dogue_de_bordeaux_0088.jpg#problem)\n",
    "\n",
    "<style>img[src$=\"#problem\"] {\n",
    "  display: center;\n",
    "  margin: 0 auto;\n",
    "  border-radius: 10px;\n",
    "  height: 400px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing YOLO files...: 100%|██████████| 3/3 [00:00<00:00, 1104.93it/s]\n",
      "Importing YOLO files...: 100%|██████████| 3/3 [00:00<00:00, 2099.25it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m annotation_df \u001b[38;5;241m=\u001b[39m \u001b[43mimporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImportYoloV5WithYaml\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/split_yolo/dataset.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_ext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_of_annotations_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_to_annotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/split_yolo/labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/helloDogBreed/lib/python3.11/site-packages/pylabel/importer.py:634\u001b[0m, in \u001b[0;36mImportYoloV5WithYaml\u001b[0;34m(yaml_file, image_ext, name_of_annotations_folder, path_to_annotations, encoding)\u001b[0m\n",
      "\u001b[1;32m    629\u001b[0m dataset2\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m splitted\n",
      "\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# This code is added so that the image ids are unique when the multiple datasets are merged\u001b[39;00m\n",
      "\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# It will take the max img_id of the first data set\u001b[39;00m\n",
      "\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# And then add that to the image ids in the second dataset so they don't collide\u001b[39;00m\n",
      "\u001b[0;32m--> 634\u001b[0m max_img_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    635\u001b[0m dataset2\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m max_img_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m    636\u001b[0m dataset\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mappend(dataset2\u001b[38;5;241m.\u001b[39mdf)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "annotation_df = importer.ImportYoloV5WithYaml(\n",
    "    \"../data/split_yolo/dataset.yaml\",\n",
    "    image_ext=\"jpg\",\n",
    "    name_of_annotations_folder=\"labels\",\n",
    "    path_to_annotations=\"../data/split_yolo/labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Verification Results:\n",
      "Classes: 18\n",
      "\n",
      "Split Status:\n",
      "\n",
      "TRAIN:\n",
      "  img_dir_exists: True\n",
      "  label_dir_exists: True\n",
      "  num_images: 1079\n",
      "  num_labels: 1079\n",
      "  sample_img_loads: True\n",
      "\n",
      "VAL:\n",
      "  img_dir_exists: True\n",
      "  label_dir_exists: True\n",
      "  num_images: 393\n",
      "  num_labels: 393\n",
      "  sample_img_loads: True\n",
      "\n",
      "TEST:\n",
      "  img_dir_exists: True\n",
      "  label_dir_exists: True\n",
      "  num_images: 279\n",
      "  num_labels: 279\n",
      "  sample_img_loads: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def verify_dataset_structure(yaml_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Verify YOLO dataset structure and paths\n",
    "\n",
    "    Args:\n",
    "        yaml_path: Path to dataset YAML file\n",
    "\n",
    "    Returns:\n",
    "        Dict with verification results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load YAML\n",
    "        with open(yaml_path, \"r\") as f:\n",
    "            cfg = yaml.safe_load(f)\n",
    "\n",
    "        base_dir = Path(yaml_path).parent\n",
    "        results = {\n",
    "            \"yaml_valid\": True,\n",
    "            \"splits\": {},\n",
    "            \"classes\": cfg.get(\"names\", []),\n",
    "            \"num_classes\": cfg.get(\"nc\", 0),\n",
    "        }\n",
    "\n",
    "        # Check each split\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            split_path = Path(cfg.get(split, \"\"))\n",
    "            img_dir = base_dir / \"images\" / split\n",
    "            label_dir = base_dir / \"labels\" / split\n",
    "\n",
    "            results[\"splits\"][split] = {\n",
    "                \"img_dir_exists\": img_dir.exists(),\n",
    "                \"label_dir_exists\": label_dir.exists(),\n",
    "                \"num_images\": len(list(img_dir.glob(\"*.jpg\")))\n",
    "                if img_dir.exists()\n",
    "                else 0,\n",
    "                \"num_labels\": len(list(label_dir.glob(\"*.txt\")))\n",
    "                if label_dir.exists()\n",
    "                else 0,\n",
    "            }\n",
    "\n",
    "            # Verify sample image loads\n",
    "            if results[\"splits\"][split][\"num_images\"] > 0:\n",
    "                sample_img = next(img_dir.glob(\"*.jpg\"))\n",
    "                img = cv2.imread(str(sample_img))\n",
    "                results[\"splits\"][split][\"sample_img_loads\"] = img is not None\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "# Test dataset structure\n",
    "yaml_path = \"../data/split_yolo/dataset.yaml\"\n",
    "results = verify_dataset_structure(yaml_path)\n",
    "print(\"Dataset Verification Results:\")\n",
    "print(f\"Classes: {len(results['classes'])}\")\n",
    "print(\"\\nSplit Status:\")\n",
    "for split, info in results[\"splits\"].items():\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    for k, v in info.items():\n",
    "        print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing YOLO files...: 100%|██████████| 3/3 [00:00<00:00, 1104.93it/s]\n",
      "Importing YOLO files...: 100%|██████████| 3/3 [00:00<00:00, 2099.25it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m annotation_df \u001b[38;5;241m=\u001b[39m \u001b[43mimporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImportYoloV5WithYaml\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/split_yolo/dataset.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_ext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_of_annotations_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_to_annotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/split_yolo/labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/helloDogBreed/lib/python3.11/site-packages/pylabel/importer.py:634\u001b[0m, in \u001b[0;36mImportYoloV5WithYaml\u001b[0;34m(yaml_file, image_ext, name_of_annotations_folder, path_to_annotations, encoding)\u001b[0m\n\u001b[1;32m    629\u001b[0m dataset2\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m splitted\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# This code is added so that the image ids are unique when the multiple datasets are merged\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# It will take the max img_id of the first data set\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# And then add that to the image ids in the second dataset so they don't collide\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m max_img_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m dataset2\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m max_img_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m dataset\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mappend(dataset2\u001b[38;5;241m.\u001b[39mdf)\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "annotation_df = importer.ImportYoloV5WithYaml(\n",
    "    \"../data/split_yolo/dataset.yaml\",\n",
    "    image_ext=\"jpg\",\n",
    "    name_of_annotations_folder=\"labels\",\n",
    "    path_to_annotations=\"../data/split_yolo/labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first annotation file\n",
    "\n",
    "annotation_file = annotation_files[0]\n",
    "\n",
    "with open(annotation_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms as T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/helloDogBreed/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/helloDogBreed/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /Users/tillmeineke/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n",
      "100%|██████████| 136M/136M [00:21<00:00, 6.69MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.ssd300_vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3-4): 2 x Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = Image.open(\"../data/raw/143_dog_breeds/bull_terrier/Image_100.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.ToTensor()\n",
    "img = transform(ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = model([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[1.3343e+01, 3.8110e+00, 4.1904e+02, 3.2028e+02],\n",
       "          [1.2582e+01, 0.0000e+00, 4.2223e+02, 3.2378e+02],\n",
       "          [2.3101e+02, 0.0000e+00, 3.8221e+02, 5.4556e+01],\n",
       "          [2.6924e+02, 1.4317e+02, 3.2277e+02, 1.8152e+02],\n",
       "          [2.7222e+02, 1.5367e+02, 2.9613e+02, 1.7300e+02],\n",
       "          [2.9227e+02, 1.3697e+02, 3.3680e+02, 1.8014e+02],\n",
       "          [3.1990e+02, 0.0000e+00, 3.7721e+02, 4.5855e+01],\n",
       "          [2.8552e+02, 1.5603e+02, 3.0297e+02, 1.7224e+02],\n",
       "          [3.0318e+02, 0.0000e+00, 3.4836e+02, 4.6430e+01],\n",
       "          [2.5980e+02, 1.5238e+02, 3.0527e+02, 1.8938e+02],\n",
       "          [2.8394e+02, 1.4727e+02, 3.0438e+02, 1.6488e+02],\n",
       "          [2.2789e+02, 0.0000e+00, 2.8792e+02, 5.1474e+01],\n",
       "          [2.1617e+02, 0.0000e+00, 3.1443e+02, 1.0101e+02],\n",
       "          [2.6220e+02, 0.0000e+00, 3.6315e+02, 1.0493e+02],\n",
       "          [2.7507e+02, 0.0000e+00, 3.2826e+02, 4.4219e+01],\n",
       "          [2.7581e+02, 1.6565e+02, 2.9429e+02, 1.8070e+02],\n",
       "          [2.3164e+02, 1.7053e+02, 2.8567e+02, 2.1010e+02],\n",
       "          [1.3062e+02, 0.0000e+00, 3.4046e+02, 6.2323e+01],\n",
       "          [2.9803e+02, 1.4600e+02, 3.1786e+02, 1.6510e+02],\n",
       "          [3.5908e+02, 0.0000e+00, 3.9798e+02, 3.9326e+01],\n",
       "          [1.3536e+01, 0.0000e+00, 4.2277e+02, 3.2359e+02],\n",
       "          [3.0651e+02, 1.4458e+02, 3.2918e+02, 1.6622e+02],\n",
       "          [2.9859e+02, 1.5461e+02, 3.1714e+02, 1.7373e+02],\n",
       "          [1.6391e+02, 0.0000e+00, 2.6542e+02, 1.0026e+02],\n",
       "          [2.8776e+02, 1.6796e+02, 3.0233e+02, 1.8050e+02],\n",
       "          [2.2260e+02, 1.8119e+02, 2.6795e+02, 2.1908e+02],\n",
       "          [3.1070e+02, 2.0362e+02, 3.5544e+02, 2.5016e+02],\n",
       "          [2.4795e+02, 2.8606e-01, 3.8309e+02, 1.9431e+02],\n",
       "          [2.5322e+02, 0.0000e+00, 3.5963e+02, 3.4439e+01],\n",
       "          [2.8230e+02, 1.2930e+02, 3.3028e+02, 1.6531e+02],\n",
       "          [2.0771e+02, 0.0000e+00, 2.5201e+02, 4.8586e+01],\n",
       "          [2.6299e+02, 1.6562e+02, 2.8213e+02, 1.8161e+02],\n",
       "          [2.7265e+02, 0.0000e+00, 3.2766e+02, 4.1222e+01],\n",
       "          [3.0695e+02, 1.5177e+02, 3.2807e+02, 1.7852e+02],\n",
       "          [2.0011e+02, 1.8534e+00, 3.2877e+02, 1.8576e+02],\n",
       "          [2.9971e+02, 1.6637e+02, 3.1547e+02, 1.8075e+02],\n",
       "          [3.4906e+02, 0.0000e+00, 3.9211e+02, 4.5745e+01],\n",
       "          [1.5537e+02, 3.0727e+00, 1.9348e+02, 4.3266e+01],\n",
       "          [3.0747e+02, 1.3850e+02, 3.2776e+02, 1.5471e+02],\n",
       "          [6.2441e+01, 0.0000e+00, 4.0007e+02, 1.1235e+02],\n",
       "          [2.3249e+02, 1.8830e+02, 2.5840e+02, 2.1026e+02],\n",
       "          [2.3351e+02, 1.8147e+02, 2.5623e+02, 2.0206e+02],\n",
       "          [2.9994e+02, 1.3859e+02, 3.1775e+02, 1.5367e+02],\n",
       "          [1.5335e+02, 0.0000e+00, 3.9287e+02, 1.2637e+02],\n",
       "          [2.6236e+02, 1.7437e+02, 2.8168e+02, 1.9079e+02],\n",
       "          [2.4893e+02, 1.8307e+02, 2.6896e+02, 2.0046e+02],\n",
       "          [2.9462e+02, 3.2157e+02, 3.4545e+02, 3.4781e+02],\n",
       "          [7.0405e+01, 0.0000e+00, 1.6658e+02, 1.1042e+02],\n",
       "          [3.1911e+02, 2.1794e+02, 3.4514e+02, 2.4276e+02],\n",
       "          [1.8000e+02, 0.0000e+00, 2.3357e+02, 4.3899e+01],\n",
       "          [2.6137e+02, 1.8292e+02, 2.8209e+02, 2.0022e+02],\n",
       "          [3.2801e+02, 2.1350e+02, 3.5652e+02, 2.4334e+02],\n",
       "          [2.5883e+02, 1.7222e+02, 4.5000e+02, 3.1163e+02],\n",
       "          [4.3085e+02, 3.2183e+02, 4.4781e+02, 3.5000e+02],\n",
       "          [2.8175e+02, 1.5951e+02, 3.3123e+02, 2.0206e+02],\n",
       "          [3.1682e+02, 0.0000e+00, 4.1000e+02, 1.1666e+02],\n",
       "          [2.4792e+02, 1.9213e+02, 2.6935e+02, 2.0957e+02],\n",
       "          [2.6377e+02, 1.5542e+02, 2.8306e+02, 1.7201e+02],\n",
       "          [2.1002e+02, 1.1226e+02, 4.0998e+02, 2.7713e+02],\n",
       "          [6.8547e+01, 0.0000e+00, 2.7743e+02, 8.3630e+01],\n",
       "          [1.2419e+02, 0.0000e+00, 2.1691e+02, 1.0933e+02],\n",
       "          [2.6360e+02, 1.1591e+01, 3.3948e+02, 5.9765e+01],\n",
       "          [2.7768e+02, 1.7590e+02, 2.9401e+02, 1.9016e+02],\n",
       "          [2.8751e+02, 1.3944e+02, 3.0515e+02, 1.5427e+02],\n",
       "          [2.0448e+01, 1.7481e+01, 6.6746e+01, 7.6678e+01],\n",
       "          [2.5563e+02, 1.7058e+02, 3.0423e+02, 2.0962e+02],\n",
       "          [8.9599e+01, 0.0000e+00, 1.2982e+02, 4.6117e+01],\n",
       "          [1.1074e+02, 6.2545e+00, 1.5678e+02, 7.4158e+01],\n",
       "          [1.5788e+01, 5.4805e+00, 1.4212e+02, 1.6170e+02],\n",
       "          [1.8810e+02, 0.0000e+00, 2.7859e+02, 3.2221e+01],\n",
       "          [1.7995e+02, 1.7872e+02, 3.4846e+02, 3.0477e+02],\n",
       "          [1.5779e+02, 0.0000e+00, 2.0221e+02, 4.8908e+01],\n",
       "          [4.3875e+02, 3.1689e+02, 4.5000e+02, 3.4703e+02],\n",
       "          [2.9460e+02, 0.0000e+00, 3.9775e+02, 3.1573e+01],\n",
       "          [1.0252e+02, 1.7807e+02, 1.5041e+02, 2.2146e+02],\n",
       "          [2.4851e+02, 1.7270e+02, 2.6984e+02, 1.9145e+02],\n",
       "          [2.9712e+02, 1.7593e+02, 3.1569e+02, 1.9073e+02],\n",
       "          [3.0856e+02, 1.6558e+02, 3.3034e+02, 1.7940e+02],\n",
       "          [3.7462e+02, 3.2661e+02, 3.8756e+02, 3.3909e+02],\n",
       "          [2.8577e+02, 1.7574e+02, 3.0329e+02, 1.9032e+02],\n",
       "          [3.5528e+02, 3.1820e+02, 4.0916e+02, 3.4676e+02],\n",
       "          [3.1991e+02, 2.0610e+02, 3.4464e+02, 2.3176e+02],\n",
       "          [2.9449e+02, 3.2219e+02, 3.2332e+02, 3.4295e+02],\n",
       "          [2.3233e+02, 1.8906e+02, 2.8248e+02, 2.2402e+02],\n",
       "          [3.0654e+02, 1.7298e+02, 3.2963e+02, 1.9312e+02],\n",
       "          [3.1816e+02, 1.4599e+02, 3.3551e+02, 1.6469e+02],\n",
       "          [1.0856e+02, 0.0000e+00, 1.5936e+02, 3.9958e+01],\n",
       "          [2.2330e+02, 1.8723e+02, 2.4880e+02, 2.1060e+02],\n",
       "          [2.9433e+02, 1.7081e+02, 3.3779e+02, 2.1234e+02],\n",
       "          [1.3492e+02, 0.0000e+00, 1.7773e+02, 4.8622e+01],\n",
       "          [2.5892e+02, 1.9134e+02, 2.8221e+02, 2.1023e+02],\n",
       "          [3.0577e+02, 1.2685e+02, 3.4787e+02, 1.6569e+02],\n",
       "          [3.3961e+02, 3.2181e+02, 3.4643e+02, 3.2696e+02],\n",
       "          [1.6032e+02, 1.6491e+01, 1.8603e+02, 4.1981e+01],\n",
       "          [7.3408e+01, 0.0000e+00, 1.4660e+02, 3.0531e+01],\n",
       "          [3.6839e+02, 0.0000e+00, 4.1694e+02, 4.1337e+01],\n",
       "          [3.0225e+02, 1.1187e+01, 3.4683e+02, 1.0853e+02],\n",
       "          [3.5140e+02, 3.2060e+02, 3.5788e+02, 3.2588e+02],\n",
       "          [2.3495e+02, 1.9843e+02, 2.5811e+02, 2.1793e+02],\n",
       "          [2.9135e+01, 1.6943e+02, 4.1532e+02, 3.4030e+02],\n",
       "          [3.1897e+02, 1.5481e+02, 3.3542e+02, 1.7410e+02],\n",
       "          [6.3881e+01, 0.0000e+00, 1.0454e+02, 4.8066e+01],\n",
       "          [2.7713e+02, 1.8341e+02, 2.9272e+02, 1.9856e+02],\n",
       "          [2.9614e+02, 2.1905e+02, 3.4248e+02, 2.5681e+02],\n",
       "          [2.2358e+02, 1.6401e+02, 2.7018e+02, 2.0181e+02],\n",
       "          [2.3357e+02, 1.5561e+02, 2.8241e+02, 1.9281e+02],\n",
       "          [1.3281e+02, 0.0000e+00, 2.4163e+02, 5.0149e+01],\n",
       "          [3.0642e+02, 1.4995e+02, 3.4681e+02, 1.9603e+02],\n",
       "          [2.9626e+02, 0.0000e+00, 4.1564e+02, 2.1316e+02],\n",
       "          [3.2057e+02, 2.1632e+02, 3.6240e+02, 2.6168e+02],\n",
       "          [3.1694e+02, 2.2766e+02, 3.4811e+02, 2.4803e+02],\n",
       "          [2.7893e+02, 1.3744e+00, 3.1016e+02, 3.2549e+01],\n",
       "          [3.0627e+02, 2.2601e+02, 3.3258e+02, 2.5065e+02],\n",
       "          [3.6409e+02, 3.2047e+02, 3.7014e+02, 3.2581e+02],\n",
       "          [2.6946e+02, 2.3384e+02, 4.5000e+02, 3.4126e+02],\n",
       "          [3.8221e+02, 3.2548e+02, 4.0110e+02, 3.3987e+02],\n",
       "          [3.0423e+02, 1.7932e+02, 3.3133e+02, 2.0413e+02],\n",
       "          [3.5039e+02, 3.2821e+02, 3.5812e+02, 3.3546e+02],\n",
       "          [3.0749e+02, 3.2403e+02, 3.3108e+02, 3.4511e+02],\n",
       "          [2.7836e+02, 9.9384e+00, 3.2190e+02, 1.0560e+02],\n",
       "          [1.3763e+02, 1.5634e+01, 3.0189e+02, 1.5591e+02],\n",
       "          [3.3776e+02, 3.2793e+02, 3.4781e+02, 3.3651e+02],\n",
       "          [1.3788e+02, 8.6817e-01, 2.4651e+02, 6.7232e+01],\n",
       "          [1.2228e+02, 1.8344e+01, 2.0541e+02, 2.2810e+02],\n",
       "          [7.4063e+01, 6.0592e+00, 1.4966e+02, 5.7975e+01],\n",
       "          [1.1127e+02, 0.0000e+00, 2.2513e+02, 1.3666e+02],\n",
       "          [2.4972e+02, 1.3767e+02, 2.9712e+02, 1.7427e+02],\n",
       "          [9.1608e+01, 1.7049e+02, 1.3898e+02, 2.1115e+02],\n",
       "          [3.4262e+02, 3.1633e+02, 3.4987e+02, 3.2178e+02],\n",
       "          [3.1848e+02, 1.3828e+02, 3.3558e+02, 1.5482e+02],\n",
       "          [2.4806e+02, 2.0060e+02, 2.6997e+02, 2.1704e+02],\n",
       "          [3.5582e+02, 3.2203e+02, 3.6505e+02, 3.2811e+02],\n",
       "          [1.7260e+02, 2.1767e+01, 2.6035e+02, 2.2386e+02],\n",
       "          [9.0072e+01, 1.3356e+01, 1.3366e+02, 9.3721e+01],\n",
       "          [3.1804e+02, 1.3074e+01, 3.4257e+02, 4.6835e+01],\n",
       "          [3.4217e+02, 3.2197e+02, 3.5429e+02, 3.2854e+02],\n",
       "          [2.6089e+02, 1.2887e+02, 3.0789e+02, 1.6558e+02],\n",
       "          [2.9424e+02, 1.8243e+02, 3.1810e+02, 2.0123e+02],\n",
       "          [1.1690e+02, 1.8114e+02, 1.3711e+02, 2.0119e+02],\n",
       "          [3.5287e+02, 3.1522e+02, 3.6023e+02, 3.2062e+02],\n",
       "          [2.5757e+02, 1.5814e+01, 2.7771e+02, 4.8194e+01],\n",
       "          [3.2540e+02, 7.4468e+00, 3.6984e+02, 1.0823e+02],\n",
       "          [1.2043e+02, 1.9297e+02, 1.3545e+02, 2.0935e+02],\n",
       "          [2.8764e+02, 1.7611e+02, 3.0703e+02, 1.8858e+02],\n",
       "          [3.6552e+02, 3.2752e+02, 3.7511e+02, 3.3881e+02],\n",
       "          [2.4529e+01, 0.0000e+00, 1.2239e+02, 1.1496e+02],\n",
       "          [3.5718e+02, 3.1257e+02, 3.6549e+02, 3.1804e+02],\n",
       "          [3.1783e+02, 3.2497e+02, 3.3946e+02, 3.4563e+02],\n",
       "          [4.1936e+02, 3.1544e+02, 4.5000e+02, 3.4961e+02],\n",
       "          [2.9522e+02, 1.9007e+02, 3.4003e+02, 2.2657e+02],\n",
       "          [1.1542e+02, 1.8925e+02, 1.6057e+02, 2.3283e+02],\n",
       "          [3.4747e+02, 3.1314e+02, 3.5600e+02, 3.1872e+02],\n",
       "          [2.3085e+02, 2.2942e-01, 2.6287e+02, 3.0329e+01],\n",
       "          [3.5189e+02, 3.2442e+02, 3.6009e+02, 3.3090e+02],\n",
       "          [3.2541e+02, 5.2338e+00, 3.5747e+02, 3.9704e+01],\n",
       "          [1.3434e+02, 2.0638e+02, 1.7486e+02, 2.5013e+02],\n",
       "          [2.7265e+02, 0.0000e+00, 3.2766e+02, 4.1222e+01],\n",
       "          [3.2372e+02, 1.4203e+02, 4.5000e+02, 2.7243e+02],\n",
       "          [0.0000e+00, 0.0000e+00, 9.5080e+01, 1.2637e+02],\n",
       "          [3.3947e+02, 3.2438e+02, 3.4983e+02, 3.3154e+02],\n",
       "          [2.9058e+02, 3.1148e+02, 4.3678e+02, 3.4785e+02],\n",
       "          [2.8569e+02, 1.8268e+02, 3.0428e+02, 1.9919e+02],\n",
       "          [4.4142e+02, 3.3925e+02, 4.5000e+02, 3.5000e+02],\n",
       "          [3.0872e+02, 6.5888e+00, 3.2882e+02, 3.8209e+01],\n",
       "          [3.3905e+02, 6.8831e+00, 3.6770e+02, 4.2022e+01],\n",
       "          [3.8215e+01, 1.8257e+02, 2.0079e+02, 3.0817e+02],\n",
       "          [2.5460e+02, 5.8162e-01, 2.8206e+02, 3.3029e+01],\n",
       "          [1.1281e+02, 1.5833e+02, 3.4885e+02, 2.5519e+02],\n",
       "          [1.1538e+02, 4.6745e+01, 1.5955e+02, 9.1638e+01],\n",
       "          [3.4291e+02, 0.0000e+00, 4.2643e+02, 8.5908e+01],\n",
       "          [3.1107e+02, 1.7994e+02, 3.5034e+02, 2.2370e+02],\n",
       "          [3.2340e+02, 1.9086e+02, 3.6000e+02, 2.3908e+02],\n",
       "          [2.7508e+02, 1.3986e+02, 2.9429e+02, 1.5507e+02],\n",
       "          [3.6958e+02, 3.1247e+02, 3.7878e+02, 3.1810e+02],\n",
       "          [3.6980e+02, 3.2138e+02, 3.7909e+02, 3.2789e+02],\n",
       "          [3.6474e+02, 3.2810e+02, 3.7106e+02, 3.3545e+02],\n",
       "          [2.9320e+02, 1.1650e+02, 3.3955e+02, 1.5473e+02],\n",
       "          [3.6611e+02, 3.1529e+02, 3.7309e+02, 3.2056e+02],\n",
       "          [3.0435e+02, 2.2059e+02, 3.3659e+02, 2.3769e+02],\n",
       "          [5.3442e+01, 2.3958e+01, 1.6052e+02, 2.2349e+02],\n",
       "          [3.2664e+02, 3.2144e+02, 3.3455e+02, 3.2741e+02],\n",
       "          [1.1767e+02, 1.2419e+02, 1.6030e+02, 1.7118e+02],\n",
       "          [3.0372e+02, 1.9903e+02, 3.3109e+02, 2.2068e+02],\n",
       "          [1.4270e+02, 8.7785e+00, 1.8630e+02, 5.5099e+01],\n",
       "          [2.6585e+02, 1.5014e+02, 2.8180e+02, 1.6407e+02],\n",
       "          [2.5933e+02, 8.2137e+00, 3.1132e+02, 4.8991e+01],\n",
       "          [3.0329e+02, 1.8260e+02, 3.9919e+02, 2.7147e+02],\n",
       "          [1.0327e+02, 1.7158e+02, 1.2796e+02, 1.9314e+02],\n",
       "          [2.5092e+02, 1.6596e+02, 2.6933e+02, 1.8230e+02],\n",
       "          [1.1767e+02, 1.2419e+02, 1.6030e+02, 1.7118e+02],\n",
       "          [1.1420e+02, 0.0000e+00, 2.0399e+02, 2.6695e+01],\n",
       "          [3.3087e+02, 3.2522e+02, 3.5291e+02, 3.4182e+02],\n",
       "          [3.2007e+02, 1.6405e+02, 3.3630e+02, 1.8300e+02],\n",
       "          [3.7598e+02, 3.1773e+02, 3.8515e+02, 3.2486e+02],\n",
       "          [4.2742e+02, 2.6017e+02, 4.5000e+02, 3.5000e+02],\n",
       "          [3.0564e+02, 2.0852e+02, 3.3126e+02, 2.2778e+02],\n",
       "          [4.2981e+02, 3.1620e+02, 4.4617e+02, 3.3404e+02],\n",
       "          [1.4198e+01, 8.0605e+00, 2.4742e+02, 9.0458e+01],\n",
       "          [3.6216e+02, 0.0000e+00, 4.4697e+02, 1.1400e+02],\n",
       "          [3.7511e+02, 3.2483e+02, 3.8409e+02, 3.3429e+02]]),\n",
       "  'scores': tensor([0.9244, 0.1176, 0.0655, 0.0653, 0.0536, 0.0532, 0.0529, 0.0513, 0.0511,\n",
       "          0.0503, 0.0503, 0.0493, 0.0478, 0.0473, 0.0452, 0.0448, 0.0443, 0.0440,\n",
       "          0.0432, 0.0431, 0.0426, 0.0423, 0.0416, 0.0414, 0.0408, 0.0403, 0.0383,\n",
       "          0.0380, 0.0380, 0.0372, 0.0364, 0.0350, 0.0349, 0.0348, 0.0348, 0.0341,\n",
       "          0.0337, 0.0327, 0.0325, 0.0325, 0.0317, 0.0316, 0.0315, 0.0313, 0.0309,\n",
       "          0.0309, 0.0308, 0.0300, 0.0297, 0.0295, 0.0290, 0.0288, 0.0284, 0.0281,\n",
       "          0.0277, 0.0276, 0.0276, 0.0271, 0.0270, 0.0269, 0.0269, 0.0267, 0.0265,\n",
       "          0.0264, 0.0262, 0.0262, 0.0260, 0.0253, 0.0249, 0.0249, 0.0248, 0.0244,\n",
       "          0.0243, 0.0238, 0.0232, 0.0231, 0.0225, 0.0224, 0.0224, 0.0223, 0.0220,\n",
       "          0.0218, 0.0217, 0.0214, 0.0214, 0.0212, 0.0212, 0.0210, 0.0207, 0.0206,\n",
       "          0.0203, 0.0200, 0.0200, 0.0199, 0.0199, 0.0196, 0.0194, 0.0191, 0.0191,\n",
       "          0.0190, 0.0190, 0.0189, 0.0189, 0.0188, 0.0188, 0.0183, 0.0180, 0.0173,\n",
       "          0.0173, 0.0172, 0.0171, 0.0169, 0.0168, 0.0168, 0.0166, 0.0165, 0.0164,\n",
       "          0.0164, 0.0163, 0.0163, 0.0163, 0.0163, 0.0162, 0.0162, 0.0161, 0.0160,\n",
       "          0.0158, 0.0158, 0.0158, 0.0157, 0.0157, 0.0156, 0.0155, 0.0154, 0.0153,\n",
       "          0.0153, 0.0153, 0.0153, 0.0152, 0.0152, 0.0151, 0.0150, 0.0149, 0.0148,\n",
       "          0.0148, 0.0147, 0.0146, 0.0146, 0.0146, 0.0146, 0.0146, 0.0146, 0.0145,\n",
       "          0.0145, 0.0145, 0.0144, 0.0144, 0.0143, 0.0143, 0.0143, 0.0141, 0.0141,\n",
       "          0.0140, 0.0140, 0.0139, 0.0139, 0.0138, 0.0138, 0.0138, 0.0136, 0.0136,\n",
       "          0.0135, 0.0135, 0.0135, 0.0135, 0.0134, 0.0134, 0.0134, 0.0133, 0.0133,\n",
       "          0.0133, 0.0133, 0.0133, 0.0132, 0.0132, 0.0132, 0.0132, 0.0131, 0.0131,\n",
       "          0.0131, 0.0130, 0.0130, 0.0130, 0.0129, 0.0129, 0.0129, 0.0129, 0.0129,\n",
       "          0.0128, 0.0127]),\n",
       "  'labels': tensor([18, 19,  1, 56, 56, 56,  1, 56,  1, 56, 56,  1,  1,  1,  1, 56, 56,  1,\n",
       "          56, 56,  1, 56, 56,  1, 56, 56, 56,  1,  1, 56,  1, 56, 56, 56,  1, 56,\n",
       "           1, 16, 56, 18, 56, 56, 56,  1, 56, 56, 24,  1, 56,  1, 56, 56, 18,  1,\n",
       "          56,  1, 56, 56, 18,  1,  1,  1, 56, 56, 16, 56,  1,  1, 18,  1, 18,  1,\n",
       "           1,  1, 56, 56, 56, 56, 24, 56, 24, 56, 24, 56, 56, 56,  1, 56, 56,  1,\n",
       "          56, 56, 20, 16,  1,  1,  1, 20, 56, 18, 56,  1, 56, 56, 56, 56,  1, 56,\n",
       "          18, 56, 56, 56, 56, 20, 18, 24, 56, 20, 24,  1,  1, 20, 18,  1,  1, 18,\n",
       "          56, 56, 20, 56, 56, 20,  1,  1,  1, 20, 56, 56, 56, 20,  1,  1, 56, 57,\n",
       "          24,  1, 20, 24,  1, 56, 56, 20,  1, 20,  1, 16, 64, 18, 18, 20, 34, 56,\n",
       "           1,  1,  1, 18,  1, 18,  1, 20, 56, 56, 56, 20, 20, 20, 56, 20, 56, 18,\n",
       "          20, 48, 56, 16, 56,  1, 18, 56, 56, 49,  1, 24, 56, 20,  1, 56,  1, 18,\n",
       "           1, 16])}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boxes', 'scores', 'labels'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes, scores, labels = prediction[0][\"boxes\"], prediction[0][\"scores\"], prediction[0][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9244, 0.1176, 0.0655, 0.0653, 0.0536, 0.0532, 0.0529, 0.0513, 0.0511,\n",
       "        0.0503, 0.0503, 0.0493, 0.0478, 0.0473, 0.0452, 0.0448, 0.0443, 0.0440,\n",
       "        0.0432, 0.0431, 0.0426, 0.0423, 0.0416, 0.0414, 0.0408, 0.0403, 0.0383,\n",
       "        0.0380, 0.0380, 0.0372, 0.0364, 0.0350, 0.0349, 0.0348, 0.0348, 0.0341,\n",
       "        0.0337, 0.0327, 0.0325, 0.0325, 0.0317, 0.0316, 0.0315, 0.0313, 0.0309,\n",
       "        0.0309, 0.0308, 0.0300, 0.0297, 0.0295, 0.0290, 0.0288, 0.0284, 0.0281,\n",
       "        0.0277, 0.0276, 0.0276, 0.0271, 0.0270, 0.0269, 0.0269, 0.0267, 0.0265,\n",
       "        0.0264, 0.0262, 0.0262, 0.0260, 0.0253, 0.0249, 0.0249, 0.0248, 0.0244,\n",
       "        0.0243, 0.0238, 0.0232, 0.0231, 0.0225, 0.0224, 0.0224, 0.0223, 0.0220,\n",
       "        0.0218, 0.0217, 0.0214, 0.0214, 0.0212, 0.0212, 0.0210, 0.0207, 0.0206,\n",
       "        0.0203, 0.0200, 0.0200, 0.0199, 0.0199, 0.0196, 0.0194, 0.0191, 0.0191,\n",
       "        0.0190, 0.0190, 0.0189, 0.0189, 0.0188, 0.0188, 0.0183, 0.0180, 0.0173,\n",
       "        0.0173, 0.0172, 0.0171, 0.0169, 0.0168, 0.0168, 0.0166, 0.0165, 0.0164,\n",
       "        0.0164, 0.0163, 0.0163, 0.0163, 0.0163, 0.0162, 0.0162, 0.0161, 0.0160,\n",
       "        0.0158, 0.0158, 0.0158, 0.0157, 0.0157, 0.0156, 0.0155, 0.0154, 0.0153,\n",
       "        0.0153, 0.0153, 0.0153, 0.0152, 0.0152, 0.0151, 0.0150, 0.0149, 0.0148,\n",
       "        0.0148, 0.0147, 0.0146, 0.0146, 0.0146, 0.0146, 0.0146, 0.0146, 0.0145,\n",
       "        0.0145, 0.0145, 0.0144, 0.0144, 0.0143, 0.0143, 0.0143, 0.0141, 0.0141,\n",
       "        0.0140, 0.0140, 0.0139, 0.0139, 0.0138, 0.0138, 0.0138, 0.0136, 0.0136,\n",
       "        0.0135, 0.0135, 0.0135, 0.0135, 0.0134, 0.0134, 0.0134, 0.0133, 0.0133,\n",
       "        0.0133, 0.0133, 0.0133, 0.0132, 0.0132, 0.0132, 0.0132, 0.0131, 0.0131,\n",
       "        0.0131, 0.0130, 0.0130, 0.0130, 0.0129, 0.0129, 0.0129, 0.0129, 0.0129,\n",
       "        0.0128, 0.0127])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 19,  1, 56, 56, 56,  1, 56,  1, 56, 56,  1,  1,  1,  1, 56, 56,  1,\n",
       "        56, 56,  1, 56, 56,  1, 56, 56, 56,  1,  1, 56,  1, 56, 56, 56,  1, 56,\n",
       "         1, 16, 56, 18, 56, 56, 56,  1, 56, 56, 24,  1, 56,  1, 56, 56, 18,  1,\n",
       "        56,  1, 56, 56, 18,  1,  1,  1, 56, 56, 16, 56,  1,  1, 18,  1, 18,  1,\n",
       "         1,  1, 56, 56, 56, 56, 24, 56, 24, 56, 24, 56, 56, 56,  1, 56, 56,  1,\n",
       "        56, 56, 20, 16,  1,  1,  1, 20, 56, 18, 56,  1, 56, 56, 56, 56,  1, 56,\n",
       "        18, 56, 56, 56, 56, 20, 18, 24, 56, 20, 24,  1,  1, 20, 18,  1,  1, 18,\n",
       "        56, 56, 20, 56, 56, 20,  1,  1,  1, 20, 56, 56, 56, 20,  1,  1, 56, 57,\n",
       "        24,  1, 20, 24,  1, 56, 56, 20,  1, 20,  1, 16, 64, 18, 18, 20, 34, 56,\n",
       "         1,  1,  1, 18,  1, 18,  1, 20, 56, 56, 56, 20, 20, 20, 56, 20, 56, 18,\n",
       "        20, 48, 56, 16, 56,  1, 18, 56, 56, 49,  1, 24, 56, 20,  1, 56,  1, 18,\n",
       "         1, 16])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helloDogBreed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
